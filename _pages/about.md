---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

<font face="é»‘ä½“" >å¼ ä¸‰ä¹‰</font>,ä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€ï¼Œä¿¡æ¯å®‰å…¨å›½å®¶é‡ç‚¹å®éªŒå®¤ï¼Œç‰¹åˆ«ç ”ç©¶åŠ©ç†ã€‚å¤©æ´¥å¤§å­¦åšå£«ï¼Œç¾å›½ä¸­ä½›ç½—é‡Œè¾¾å¤§å­¦è”åˆåŸ¹å…»åšå£«ã€‚ä¸»æŒæ‰¿æ‹…äº†å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´é¡¹ç›®ã€åšå£«åç§‘å­¦åŸºé‡‘é¢ä¸Šé¡¹ç›®ã€
  ç§‘æŠ€éƒ¨é‡ç‚¹ç ”å‘é¡¹ç›®å­è¯¾é¢˜ã€‚  ä¸»è¦ç ”ç©¶æ–¹å‘æ˜¯äººå·¥æ™ºèƒ½ã€è®¡ç®—æœºè§†è§‰ã€äººç‰©å›¾åƒæ™ºèƒ½æ„ŸçŸ¥ï¼Œ
  åœ¨IEEE TIPã€T-CSVTã€CVPRç­‰å›½å†…å¤–å­¦æœ¯æœŸåˆŠå’Œä¼šè®®ä¸Šå‘è¡¨è®ºæ–‡9ç¯‡ï¼Œå…¶ä¸­ä»¥ç¬¬ä¸€ä½œè€…å‘è¡¨IEEE Trans. 3ç¯‡ï¼Œå¹¶æ‹…ä»»äº†IEEE TIP/TMM/TCSVTã€CVPRã€ACM MMã€AAAIã€ICCVç­‰å›½é™…æœŸåˆŠå’Œä¼šè®®çš„å®¡ç¨¿äººã€‚æ›¾è£è·å…¨å›½åšå£«åäººå·¥æ™ºèƒ½å‘å±•ä¸åº”ç”¨è®ºå›ä¼˜ç§€è®ºæ–‡äºŒç­‰å¥–ã€åŒ—äº¬å›¾è±¡å›¾å½¢å­¦å­¦ä¼šBSIG2022å¹´ä¼˜ç§€åšå£«è®ºæ–‡æåå¥–ç­‰ã€‚


# ğŸ”¥ News

- *2022*: &nbsp; Two papers are accepted by IEEE Transactions on Image Processing (TIP) 2022.

- *2021*: &nbsp; Our text detection paper is accepted by CVPR 2021.

- *2020*: &nbsp; One human parsing paper is accepted by TCSVT -2020.

- *2019*: &nbsp;One co-author's paper is accepted by IEEE Transactions on Geoscience and Remote Sensing (T-GRS).

- *2019*: &nbsp; One paper is accepted in T-CSVT 2019.

- *2018*: &nbsp; One paper is accepted in Neurocomputing 2018.
# ğŸ“ Selected Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIP 2022</div><img src='images/first-serial-edge.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[AIParsing: Anchor-free Instance-level Human Parsing](https://arxiv.org/abs/2207.06854)

**Sanyi Zhang**, Xiaochun Cao, Guo-Jun Qi, Zhanjie Song, and Jie Zhou

[**Code**](https://github.com/31sy/AIParsing) / [**Paper**](https://arxiv.org/abs/2207.06854) / [**Poster**](images/TIP-AIParsing.jpeg) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE Transactions on Image Processing (TIP) 2022,  
<font color=purple>Impact factor: 10.6</font>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIP 2022</div><img src='images/ACE.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[ACE: Anchor-free Corner Evolution for Real-time Arbitrarily-oriented Object Detection](https://ieeexplore.ieee.org/abstract/document/9761381)

Pengwen Dai, Siyuan Yao, Zekun Li, **Sanyi Zhang**, and Xiaochun Cao 

[**Code**]() / [**Paper**](https://ieeexplore.ieee.org/abstract/document/9761381) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE Transactions on Image Processing (TIP) 2022,
<font color=purple>Impact factor: 10.6</font>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2021</div><img src='images/motivation_v1.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[Progressive Contour Regression for Arbitrary-Shape Scene Text Detection](https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Progressive_Contour_Regression_for_Arbitrary-Shape_Scene_Text_Detection_CVPR_2021_paper.pdf)

Pengwen Dai, **Sanyi Zhang**, Hua Zhang, Xiaochun Cao 

[**Code**](https://github.com/dpengwen/PCR) / [**Paper**](https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Progressive_Contour_Regression_for_Arbitrary-Shape_Scene_Text_Detection_CVPR_2021_paper.pdf) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE CVPR 2021,
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TCSVT 2021</div><img src='images/framework_PGECNet.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[Human Parsing with Pyramidical Gather-Excite Context](https://ieeexplore.ieee.org/document/9078888/)

**Sanyi Zhang**, Guo-jun Qi, Xiaochun Cao*, Zhanjie Song, and Jie Zhou

[**Code**](https://github.com/31sy/PGECNet) / [**Paper**](https://ieeexplore.ieee.org/document/9078888) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT), 2021,
<font color=purple>Impact factor: 8.4</font>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TCSVT 2020</div><img src='images/TAN.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[Task-aware Attention Model for Clothing Attribute Prediction](https://ieeexplore.ieee.org/document/8654674)

**Sanyi Zhang**, Zhanjie Song, Xiaochun Cao*, Hua Zhang and Jie Zhou

[**Code**](https://github.com/31sy/Clothing_TAN) / [**Paper**](https://ieeexplore.ieee.org/document/8654674) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT), 2020,
<font color=purple>Impact factor: 8.4</font>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TGRS 2019</div><img src='images/LV-Net.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[Nested Network with Two-Stream Pyramid for Salient Object Detection in Optical Remote Sensing Images](https://ieeexplore.ieee.org/document/8654674)

Chongyi Li, Runmin Cong, Junhui Hou, **Sanyi Zhang**, Yue Qian, Sam Kwong

[**Code**](https://github.com/31sy/Clothing_TAN) / [**Paper**](https://ieeexplore.ieee.org/document/8654674) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE Transactions on Geoscience and Remote Sensing (T-GRS), 2019,
<font color=purple>Impact factor: 8.2</font>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NC 2018</div><img src='images/NC_first.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[Watch Fashion Shows to Tell Clothing Attributes](https://www.sciencedirect.com/science/article/pii/S092523121731860X)

**Sanyi Zhang**, Si Liu, Xiaochun Cao, Zhanjie Song* and Jie Zhou

[**Dataset**](https://tjueducn-my.sharepoint.com/:f:/g/personal/zhangsanyi_tju_edu_cn/EvKIbE0U-QVEhuXjxKk_H2QB_vLvu5Uubo1cdqlYx-xfaw) / [**Paper**](https://www.sciencedirect.com/science/article/pii/S092523121731860X) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

Neurocomputing, 2018,
<font color=purple>Impact factor: 6.0</font>
</div>
</div>

- More papers are being submitted, or please visit my [Google Scholar](https://scholar.google.com/citations?user=n8TL-xkAAAAJ&hl=en) to view all papers.

# ğŸ– Honors and Awards
- *2022.05* **åŒ—äº¬å›¾è±¡å›¾å½¢å­¦å­¦ä¼šBSIG2022å¹´ä¼˜ç§€åšå£«è®ºæ–‡æåå¥–**
- *2019.12* **å…¨å›½åšå£«åäººå·¥æ™ºèƒ½å‘å±•ä¸åº”ç”¨è®ºå› äºŒç­‰å¥–**
- *2017.12* **ä¸­ç§‘é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€ æ‰€é•¿ç‰¹åˆ«å¥–**
- *2017.10* **å¤©æ´¥å¤§å­¦åšå£«ç”Ÿè®ºå›ç”µæ°”ä¸ä¿¡æ¯å·¥ç¨‹EIEåˆ†è®ºå›å­¦æœ¯è®ºæ–‡ä¼˜ç§€å¥–**


# ğŸ“– Educations
- *2021.07 - è‡³ä»Š*,  åšå£«åï¼Œä¿¡æ¯å®‰å…¨å›½å®¶é‡ç‚¹å®éªŒå®¤ï¼Œä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€ï¼Œä¸­å›½åŒ—äº¬ï¼ŒæŒ‡å¯¼è€å¸ˆï¼šæ“æ™“æ˜¥ æ•™æˆ
- *2018.09 - 2019.09, CSCè”åŸ¹åšå£«ç”Ÿï¼Œè®¡ç®—æœºç§‘å­¦ï¼Œä¸­ä½›ç½—é‡Œè¾¾å¤§å­¦ï¼ˆUCFï¼‰ï¼Œç¾å›½å¥¥å…°å¤šï¼ŒæŒ‡å¯¼è€å¸ˆï¼šGuo-Jun Qi åŠ©ç†æ•™æˆ 
- *2015.09 - 2021.06*,  åšå£«ï¼Œä¿¡æ¯ä¸é€šä¿¡å·¥ç¨‹ï¼Œå¤©æ´¥å¤§å­¦ï¼Œä¸­å›½å¤©æ´¥ï¼ŒæŒ‡å¯¼è€å¸ˆï¼šå‘¨æ° æ•™æˆ  å®‹å æ° æ•™æˆ
- *2011.09 - 2014.07*,  ç¡•å£«ï¼Œè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ï¼Œå¤ªåŸç†å·¥å¤§å­¦ï¼Œä¸­å›½å¤ªåŸï¼ŒæŒ‡å¯¼è€å¸ˆï¼šå¼ å…´å¿  æ•™æˆ
- *2007.09 - 2011.07*,  æœ¬ç§‘ï¼Œè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ï¼Œå¤ªåŸç†å·¥å¤§å­¦ï¼Œä¸­å›½å¤ªåŸ 

# ğŸ’¬ Professional Service

- *æœŸåˆŠå®¡ç¨¿äºº*: IEEE Transactions on Image Processing (TIP), IEEE Transactions on Multimedia (TMM), IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 
ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), IEEE Computational Intelligence Magazine (CIM)
- *ä¼šè®®å®¡ç¨¿äºº*ï¼šACM MM 2020-2023, NeurIPS 2022, IEEE CVPR 2023, AAAI 2023, IJCAI 2023, ICCV 2023ï¼Œ AAAI 2024.
